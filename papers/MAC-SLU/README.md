# MAC-SLU: Multi-Intent Automotive Cabin Spoken Language Understanding Benchmark

> **ğŸ’¡ Meta Information**
>
> * **Venue:** `arXiv 2025` 
> * **Paper Type:** Benchmark
> * **Links:** [Paper (arXiv)](https://arxiv.org/abs/2512.01603) | [Code](https://github.com/Gatsby-web/MAC_SLU) | [Dataset](https://huggingface.co/datasets/Gatsby1984/MAC_SLU)
> * **Institutions:** Shanghai Jiao Tong University, AISpeech Co., Ltd., et al.
>
> **ğŸ·ï¸ Domains & Tasks**
> * `Spoken Language Understanding` `Multi-Intent Understanding` `LLMs` `Large Audio Language Models`
> * **Core Tasks:** Intent Classification, Multi-Intent Detection

### ğŸ“Œ Citation
```text
Peng, Y., Cai, C., Liu, Z., Fan, S., Jiang, S., Xu, H., et al. (2025). 
MAC-SLU: Multi-Intent Automotive Cabin Spoken Language Understanding Benchmark. 
arXiv preprint arXiv:2512.01603.
```

## Introduction

### ğŸ“ Spoken Language Understanding (SLU) - Core Definition
> Spoken Language Understanding (SLU) is a conventional paradigm for task-oriented spoken semantics extraction, which has been
widely applied in scenarios such as smart homes and automobiles to extract spoken commands from users for executing downstream tasks.

#### 1. Definition (å®šç¾©)
SLU æ˜¯ **Task-oriented (ä»»å‹™å°å‘)** å°è©±ç³»çµ±ä¸­çš„æ ¸å¿ƒç¯„å¼ï¼Œè² è²¬é€²è¡Œ **Spoken Semantics Extraction (å£èªèªæ„æå–)**ã€‚
* **The Mapping Process:** `User Speech` --(SLU)--> `Structured Semantics (Commands)`
    (ç›®æ¨™æ˜¯å°‡éçµæ§‹åŒ–çš„èªéŸ³è¨Šè™Ÿï¼Œè½‰åŒ–ç‚ºæ©Ÿå™¨å¯åŸ·è¡Œçš„çµæ§‹åŒ–æŒ‡ä»¤)

#### 2. Key Applications (ä¸»è¦æ‡‰ç”¨å ´æ™¯)
ç›®å‰å»£æ³›æ‡‰ç”¨æ–¼éœ€è¦ã€Œå…æ‰‹æŒæ“ä½œ (Hands-free)ã€çš„å ´æ™¯ï¼š
* ğŸ  **Smart Homes (æ™ºæ…§å®¶å±…):** e.g., "Turn off the lights."
* ğŸš— **Automobiles (è»Šè¼‰ç³»çµ±):** e.g., "Navigate to the nearest gas station."

#### 3. Purpose (ç›®çš„)
ç‚ºäº†åŸ·è¡Œ **Downstream Tasks (ä¸‹æ¸¸ä»»å‹™)**ã€‚
* SLU ä¸æ˜¯çµ‚é»ï¼Œè€Œæ˜¯æ‰‹æ®µã€‚å®ƒçš„æº–ç¢ºåº¦ç›´æ¥æ±ºå®šäº†ç³»çµ±èƒ½å¦æ­£ç¢ºåŸ·è¡Œä½¿ç”¨è€…çš„æ„åœ–ã€‚

### ğŸ“ SLU Architecture Evolution (SLU æ¶æ§‹æ¼”é€²)
> Traditional SLU employs a pipeline approach, first transcribing the userâ€™s spoken query into text via Automatic Speech Recognition (ASR), and then extracting semantic information through Natural Language Understanding (NLU), which typically includes Intent Classification (IC) and Slot Filling (SF). Subsequently, E2E SLU systems emerged to address the issue of error propagation from the ASR transcription process and potentially incorporate pre-trained language models (e.g., RoBERTa) to enhance performance.

#### 1. Traditional Pipeline Approach (å‚³çµ±æµæ°´ç·šå¼)
é€™æ˜¯æœ€ç¶“å…¸çš„è™•ç†æ–¹å¼ï¼Œå°‡ä»»å‹™æ‹†è§£ç‚ºå…©å€‹ç¨ç«‹éšæ®µï¼š

* **Workflow (å·¥ä½œæµç¨‹):** `Audio` --(ASR)--> `Text` --(NLU)--> `Semantics`
* **Key Components (æ ¸å¿ƒçµ„ä»¶):**
    1.  **ASR (Automatic Speech Recognition):** å°‡ä½¿ç”¨è€…çš„èªéŸ³æŸ¥è©¢è½‰éŒ„ç‚ºæ–‡å­—ã€‚
    2.  **NLU (Natural Language Understanding):** å¾è½‰éŒ„çš„æ–‡å­—ä¸­æå–èªæ„è³‡è¨Šï¼Œé€šå¸¸åŒ…å«å…©å€‹å­ä»»å‹™ï¼š
        * **IC (Intent Classification):** æ„åœ–åˆ†é¡ã€‚
        * **SF (Slot Filling):** é—œéµè©æ§½ä½å¡«å……ã€‚
* **Critical Issue (é—œéµå•é¡Œ):**
    * **Error Propagation (éŒ¯èª¤å‚³æ’­):** å¦‚æœ ASR åœ¨è½‰éŒ„éšæ®µç™¼ç”ŸéŒ¯èª¤ï¼ŒNLU éšæ®µå°±å¹¾ä¹ä¸å¯èƒ½æ­£ç¢ºåˆ†æèªæ„ã€‚

#### 2. End-to-End (E2E) SLU (ç«¯å°ç«¯å¼)
ç‚ºäº†å…‹æœå‚³çµ±æµæ°´ç·šæ–¹æ³•çš„ç¼ºé™·è€Œå‡ºç¾çš„æ–°æ¶æ§‹ã€‚

* **Core Objective (æ ¸å¿ƒç›®æ¨™):**
    * è§£æ±º ASR è½‰éŒ„éç¨‹å¸¶ä¾†çš„ **Error Propagation (éŒ¯èª¤å‚³æ’­)** å•é¡Œã€‚
* **Methodology (æ–¹æ³•è«–):**
    * ä¸å†ä¾è³´ä¸­é–“çš„æ–‡å­—è½‰éŒ„ï¼Œå˜—è©¦ç›´æ¥å¾éŸ³è¨Šç‰¹å¾µæ˜ å°„åˆ°èªæ„ã€‚
    * ç¶“å¸¸çµåˆ **Pre-trained Language Models (PLMs)**ï¼ˆæ–‡ä¸­èˆ‰ä¾‹ï¼š**RoBERTa**ï¼‰ä¾†å¢å¼·æ¨¡å‹çš„èªæ„ç†è§£æ•ˆèƒ½ã€‚

### ğŸš© Critical Challenges in LLM-based SLU (LLM æ‡‰ç”¨æ–¼ SLU çš„ç•¶å‰æŒ‘æˆ°)
> Presently, the advancement of LLMs and LALMs offers the potential for a more flexible and precise SLU. Nevertheless, research on LLM-based SLU still confronts the following two challenges: (1) Existing SLU datasets lack sufficient diversity and complexity. The widely used ATIS and SNIPS datasets contain only 16 and 7 intents, respectively, which limits the taskâ€™s difficulty, resulting in existing models already achieving over 95% accuracy in both IC and SF. SLURP dataset increases the number of intent and slot categories but remains confined to single-intent SLU tasks. (2) There is a lack of a unified benchmark for state-of-the-art (SOTA) open-source LLMs and LALMs. Although some studies have preliminarily explored the performance of LLMs like ChatGPT and Llama on certain SLU tasks, they have adopted different task formats (i.e., varying data formats, prompts, or training and alignment methods), leading to evaluation results that cannot be fairly compared. Furthermore, existing research has been limited to pipeline-based methods and LLMs, without exploring E2E approaches and the most advanced LALMs.

å„˜ç®¡ LLM å’Œ LALM å±•ç¾äº†æ¥µå¤§çš„æ½›åŠ›ï¼Œä½†ç›®å‰çš„ç ”ç©¶é¢è‡¨å…©å¤§æ ¸å¿ƒç—›é»ï¼š

#### 1. Dataset Limitation: Lack of Complexity (è³‡æ–™é›†çš„ä¾·é™æ€§)
ç¾æœ‰çš„ SLU è³‡æ–™é›†éæ–¼ç°¡å–®ï¼Œç„¡æ³•åæ˜ çœŸå¯¦å ´æ™¯çš„è¤‡é›œåº¦ï¼Œå°è‡´æ¨¡å‹èƒ½åŠ›çœ‹èµ·ä¾†ã€Œè™›é«˜ã€ã€‚
* **Saturated Benchmarks (å·²é£½å’Œçš„åŸºæº–):**
    * å¸¸ç”¨è³‡æ–™é›†å¦‚ `ATIS` (17 intents) å’Œ `SNIPS` (7 intents) åˆ†é¡éå°‘ã€‚
    * **Consequence:** ç¾æœ‰æ¨¡å‹åœ¨ IC (Intent Classification) èˆ‡ SF (Slot Filling) ä¸Šæº–ç¢ºç‡å‡å·²è¶…é **95%**ï¼Œé›£ä»¥å€åˆ†æ–°æ¨¡å‹çš„å„ªåŠ£ã€‚
* **Complexity Gap:**
    * é›–ç„¶ `SLURP` å¢åŠ äº†é¡åˆ¥æ•¸é‡ï¼Œä½†ä»ä¾·é™æ–¼ **Single-Intent (å–®ä¸€æ„åœ–)** ä»»å‹™ï¼Œç¼ºä¹å¤šæ„åœ– (Multi-Intent) çš„æŒ‘æˆ°ã€‚

#### 2. Evaluation Crisis: Lack of Unified Benchmark (ç¼ºä¹çµ±ä¸€è©•æ¸¬æ¨™æº–)
ç›®å‰çš„ SOTA æ¨¡å‹è©•æ¸¬è™•æ–¼ã€Œå„è‡ªç‚ºæ”¿ã€çš„ç‹€æ…‹ï¼Œç¼ºä¹å…¬å¹³çš„æ¯”è¼ƒåŸºæº–ã€‚
* **Inconsistent Protocols:**
    * ç¾æœ‰ç ”ç©¶é›–ç„¶æ¸¬è©¦äº† ChatGPT æˆ– Llamaï¼Œä½†ä½¿ç”¨äº†ä¸åŒçš„ Data Formatsã€Prompts æˆ– Alignment methodsã€‚
    * **Result:** è©•æ¸¬çµæœç„¡æ³•é€²è¡Œå…¬å¹³çš„æ©«å‘å°æ¯” (Unfair comparison)ã€‚
* **Scope Limitation:**
    * ç›®å‰ç ”ç©¶å¤šé›†ä¸­åœ¨ **Pipeline-based** æ–¹æ³•ï¼Œå¿½ç•¥äº† **End-to-End (E2E)** æ–¹æ³•èˆ‡æœ€å…ˆé€² **LALMs** çš„æ½›åŠ›æ¢ç´¢ã€‚

---

ğŸ’¡ Keep in Mind
é€™æ®µè©±å…¶å¯¦æ˜¯åœ¨ç‚ºä½œè€…è‡ªå·±çš„è²¢ç» **(Contribution)** é‹ªè·¯ã€‚è®€åˆ°é€™è£¡ï¼Œä½ æ‡‰è©²é æœŸé€™ç¯‡è«–æ–‡æ¥ä¸‹ä¾†æœƒæå‡ºï¼š
1.  ä¸€å€‹æ›´é›£ã€æ›´å¤šæ¨£åŒ–ï¼ˆå¯èƒ½åŒ…å« Multi-Intentï¼‰çš„æ–°è³‡æ–™é›†ã€‚
2.  ä¸€å€‹çµ±ä¸€çš„ Benchmarkï¼ŒåŒæ™‚è©•æ¸¬ Pipeline vs. E2E ä»¥åŠ LLM vs. LALMã€‚

---
### ğŸš€ Core Contributions (æ ¸å¿ƒè²¢ç»)
> This work addresses these challenges with two steps. First, we introduce the Multi-Intent Automotive Cabin Spoken Language Understanding (MAC-SLU) dataset, a novel Chinese SLU corpus to overcome the complexity limitations of existing data. Derived from real-world automotive text commands with TTS-synthesized speech, it spans 8 domains, 81 intents, 192 slots, and includes multi-intent queries with up to 5 intents, creating a more rigorous testbed. Second, we establish a unified benchmark on MAC-SLU for SOTA
open-source LLMs and LALMs. Standardizing formats, tasks, and evaluation methods enables fair comparisons and provides a dependable reference for the community.

é€™ç¯‡è«–æ–‡æå‡ºäº†å…©å¤§è§£æ±ºæ–¹æ¡ˆä¾†æ‡‰å°ç¾æœ‰ SLU ç ”ç©¶çš„ä¸è¶³ï¼š

#### 1. The MAC-SLU Dataset (å…¨æ–°çš„è³‡æ–™é›†)
ç‚ºäº†è§£æ±ºç¾æœ‰è³‡æ–™é›†ç¼ºä¹è¤‡é›œåº¦èˆ‡å¤šæ¨£æ€§çš„å•é¡Œï¼Œä½œè€…ç™¼å¸ƒäº† **Multi-Intent Automotive Cabin Spoken Language Understanding (MAC-SLU)**ã€‚
* **Language:** Chinese (ä¸­æ–‡èªæ–™)ã€‚
* **Data Source:** æºè‡ªçœŸå¯¦ä¸–ç•Œçš„è»Šè¼‰æ–‡æœ¬æŒ‡ä»¤ï¼Œä¸¦é€é TTS (Text-to-Speech) åˆæˆèªéŸ³ã€‚
* **Scale & Complexity:**
    * **8** Domains (é ˜åŸŸ)
    * **81** Intents (æ„åœ–)
    * **192** Slots (æ§½ä½)
* **Key Innovation:** åŒ…å« **Multi-intent queries (å¤šæ„åœ–æŸ¥è©¢)**ï¼Œå–®å¥æœ€å¤šåŒ…å« **5** å€‹æ„åœ–ï¼Œå»ºç«‹äº†ä¸€å€‹æ›´åš´è‹›çš„æ¸¬è©¦å¹³å° (Rigorous testbed)ã€‚

#### 2. Unified Benchmark (çµ±ä¸€çš„è©•æ¸¬åŸºæº–)
é‡å° SOTA é–‹æº LLMs å’Œ LALMs å»ºç«‹äº†çµ±ä¸€çš„è©•æ¸¬æ¨™æº–ã€‚
* **Standardization:** çµ±ä¸€äº†è³‡æ–™æ ¼å¼ (Formats)ã€ä»»å‹™å®šç¾© (Tasks) èˆ‡è©•ä¼°æ–¹æ³• (Evaluation methods)ã€‚
* **Goal:** å¯¦ç¾ **Fair Comparisons (å…¬å¹³æ¯”è¼ƒ)**ï¼Œç‚ºç¤¾ç¾¤æä¾›å¯ä¿¡è³´çš„åƒè€ƒä¾æ“šã€‚

> Our contributions include:
> - We introduce MAC-SLU, a novel Chinese multi-intent SLU dataset including complex, multi-intent queries from a real-world automotive cabin domain. MAC-SLU enables a more chanllenging evaluation of the latest LLMs and LALMs.
> - We provide a comprehensive benchmark for SOTA open-source and closed-source LLMs and LALMs, encompassing methods based on direct inference, in-context learning, and SFT, as well as both pipeline and E2E SLU task paradigms.
> - Our experiments demonstrate that (1) existing LLMs and LALMs can complete parts of the IC or SF tasks through in-context learning, yet there remains a significant performance gap compared to in-domain SFT; (2) benefiting from the avoidance of error propagation, current LALMs can already achieve performance comparable to pipeline methods.

#### 1. Dataset Contribution: MAC-SLU
ä½œè€…ç™¼å¸ƒäº†ä¸€å€‹å…¨æ–°çš„ **Chinese Multi-Intent SLU Dataset**ã€‚
* **Domain:** Real-world Automotive Cabin (çœŸå¯¦è»Šè¼‰å ´æ™¯)ã€‚
* **Characteristics:** åŒ…å« **Complex, Multi-intent queries (è¤‡é›œå¤šæ„åœ–æŸ¥è©¢)**ã€‚
* **Value:** ç›¸æ¯”æ–¼ç¾æœ‰çš„ç°¡å–®è³‡æ–™é›†ï¼Œå®ƒç‚ºæœ€æ–°çš„ LLMs å’Œ LALMs æä¾›äº†æ›´å…·æŒ‘æˆ°æ€§çš„è©•æ¸¬ç’°å¢ƒã€‚

#### 2. Comprehensive Benchmark (å…¨é¢è©•æ¸¬åŸºæº–)
å»ºç«‹äº†ä¸€å€‹æ¶µè“‹ **SOTA Open-source & Closed-source** æ¨¡å‹çš„è©•æ¸¬åŸºæº–ã€‚
* **Models Covered:** LLMs (Text-only) & LALMs (Audio-Text).
* **Methods Evaluated:**
    * Direct Inference (Zero-shot)
    * In-Context Learning (Few-shot)
    * Supervised Fine-Tuning (SFT)
* **Paradigms:** åŒæ™‚è©•æ¸¬äº† **Pipeline (ASR+NLU)** èˆ‡ **E2E (End-to-End)** å…©ç¨® SLU æ¶æ§‹ã€‚

#### 3. Key Experimental Insights (é—œéµå¯¦é©—çµè«–)
é€™éƒ¨åˆ†æ­ç¤ºäº†ç›®å‰æŠ€è¡“çš„é‚Šç•Œ (Boundaries)ï¼š
* **Gap in Learning Paradigms:**
    $$\text{Performance}\_{\text{SFT}} \gg \text{Performance}\_{\text{ICL}}$$
    * é›–ç„¶ LLMs/LALMs å¯ä»¥é€é In-context Learning (ICL) å®Œæˆéƒ¨åˆ† IC æˆ– SF ä»»å‹™ï¼Œä½†èˆ‡ **In-domain SFT** ç›¸æ¯”ä»æœ‰é¡¯è‘—å·®è·ã€‚
* **Rise of LALMs (E2E Potential):**
    ç›®å‰çš„ LALMs (Large Audio Language Models) å·²ç¶“èƒ½é”åˆ°èˆ‡ Pipeline æ–¹æ³• **Comparable (ç›¸ç•¶)** çš„æ•ˆèƒ½ã€‚
    * **Reason:** æ­¸åŠŸæ–¼ **Avoidance of Error Propagation** (E2E æ¶æ§‹é¿å…äº† ASR è½‰éŒ„éŒ¯èª¤å‚³éåˆ° NLU çš„å•é¡Œ)ã€‚
 
---
## ğŸ“Š Dataset Construction & Statistics (MAC-SLU è³‡æ–™é›†å»ºæ§‹)

<img width="1051" height="163" alt="image" src="https://github.com/user-attachments/assets/c7265932-c3af-453f-ab70-5152acb67f3d" />

### Text Data Collection

#### 1. Data Origin (æ•¸æ“šä¾†æº)
* **Source:** Real-world Automotive Cabin Scenarios (çœŸå¯¦ä¸–ç•Œçš„è»Šè¼‰å ´æ™¯)ã€‚
* **Format:** Transcribed texts of Chinese spoken commands (ä¸­æ–‡èªéŸ³æŒ‡ä»¤è½‰éŒ„æ–‡æœ¬)ã€‚
* **Scale:** åŸå§‹æ”¶é›†äº†è¶…é **20,000** æ¢èªæ–™åŠå…¶å°æ‡‰çš„ SLU è§£æçµæœã€‚

#### 2. Data Partitioning & Annotation Strategy (æ•¸æ“šåŠƒåˆ†èˆ‡æ¨™è¨»ç­–ç•¥)
ä½œè€…æ¡ç”¨äº† **Weakly Labeled (å¼±æ¨™è¨»)** ç”¨æ–¼è¨“ç·´ï¼Œ**Human Annotated (äººå·¥ç²¾æ¨™)** ç”¨æ–¼æ¸¬è©¦çš„ç­–ç•¥ï¼Œé€™æ˜¯å·¥æ¥­ç•Œå¸¸è¦‹çš„åšæ³•ã€‚

| Split | Size (Samples) | Label Quality | Method |
| :--- | :--- | :--- | :--- |
| **Training Set** | **17,997** | Weakly Labeled | éš¨æ©Ÿé¸å–ï¼Œç›´æ¥ä½¿ç”¨ç¾æœ‰çš„ SLU è§£æçµæœä½œç‚ºæ¨™ç±¤ã€‚ |
| **Validation Set**| **1,391** | Weakly Labeled | åŒä¸Šã€‚ |
| **Test Set** | **1,152** | **Clean / Gold** | ç¶“é 3 ä½æ¨™è¨»è€…äººå·¥å¯©æŸ¥èˆ‡æ¸…æ´—ã€‚ |

#### 3. Rigorous Cleaning Process for Test Set (æ¸¬è©¦é›†æ¸…æ´—æµç¨‹)
ç‚ºäº†ç¢ºä¿ Evaluation çš„æº–ç¢ºæ€§ï¼Œä½œè€…å°æ¸¬è©¦é›†é€²è¡Œäº†åš´æ ¼çš„ç¯©é¸ï¼š
* **Initial Pool:** éš¨æ©ŸæŠ½å– 1,800 æ¨£æœ¬ã€‚
* **Process:** 3 ä½æ¨™è¨»è€…é€²è¡Œå¯©æŸ¥ï¼Œç§»é™¤æˆ–ä¿®æ­£éŒ¯èª¤ (Parsing errors) èˆ‡ç©ºæ„åœ– (Blank intents)ã€‚
* **Retention Rate:** $1800 \to 1152$ (ç´„ä¿ç•™ 64%)ã€‚
    * *Insight:* é€™å€‹ç¯©é¸æ¯”ä¾‹æš—ç¤ºåŸå§‹æ•¸æ“šä¸­å­˜åœ¨ä¸€å®šæ¯”ä¾‹çš„å™ªè² (Noise)ï¼Œå› æ­¤äººå·¥æ¸…æ´—å°æ–¼å»ºç«‹å¯é çš„ Benchmark è‡³é—œé‡è¦ã€‚

### Speech Data Generation

ç‚ºäº†æ§‹å»ºèªéŸ³è³‡æ–™é›†ï¼Œä½œè€…ä¸¦æœªé‡æ–°éŒ„è£½äººè²ï¼Œè€Œæ˜¯æ¡ç”¨äº†å…ˆé€²çš„ TTS æŠ€è¡“é€²è¡Œåˆæˆï¼Œä¸¦é€éåš´è¬¹çš„ç­–ç•¥ç¢ºä¿äº†èªè€…çš„å¤šæ¨£æ€§èˆ‡å¯¦é©—çš„å…¬å¹³æ€§ã€‚

#### 1. Core Technology (æ ¸å¿ƒæŠ€è¡“)
* **TTS Model:** ä½¿ç”¨ **CosyVoice-2** æ¨¡å‹é€²è¡ŒèªéŸ³åˆæˆã€‚
* **Target Language:** Mandarin Chineseã€‚

#### 2. Speaker Embedding Source (èªè€…ç‰¹å¾µä¾†æº)
ç‚ºäº†è®“åˆæˆçš„èªéŸ³è½èµ·ä¾†åƒä¸åŒçš„äººï¼ˆè€Œä¸æ˜¯åªæœ‰ä¸€å€‹æ©Ÿå™¨äººè²éŸ³ï¼‰ï¼Œä½œè€…ä½¿ç”¨äº† **AIShell-1**ï¼ˆä¸€å€‹å»£æ³›ä½¿ç”¨çš„ä¸­æ–‡ ASR è³‡æ–™é›†ï¼‰ä½œç‚ºèªè€…ç‰¹å¾µçš„ä¾†æºã€‚

#### 3. Synthesis Strategy & Data Isolation (åˆæˆç­–ç•¥èˆ‡è³‡æ–™éš”é›¢)
é€™éƒ¨åˆ†æ˜¯å¯¦é©—è¨­è¨ˆçš„äº®é»ï¼Œæ—¨åœ¨é¿å…**è³‡æ–™æ´©éœ² (Data Leakage)**ï¼š
* **Template Extraction:** å¾ AIShell-1 çš„ `train`, `dev`, `test` ä¸‰å€‹é›†åˆä¸­ï¼Œéš¨æ©Ÿé¸å–éŸ³è¨Šç‰‡æ®µï¼Œæ§‹å»ºå‡ºä¸‰çµ„ç¨ç«‹çš„ **Speaker Templates (èªè€…æ¨¡æ¿)**ã€‚
* **Strict Isolation:**
    * åˆæˆ MAC-SLU çš„è¨“ç·´é›†æ™‚ $\to$ åªä½¿ç”¨ AIShell-1 è¨“ç·´é›†çš„èªè€…æ¨¡æ¿ã€‚
    * åˆæˆ MAC-SLU çš„æ¸¬è©¦é›†æ™‚ $\to$ åªä½¿ç”¨ AIShell-1 æ¸¬è©¦é›†çš„èªè€…æ¨¡æ¿ã€‚
* **Goal:**
    1. **Ensure Diversity:** ç¢ºä¿èªæ–™åº«ä¸­åŒ…å«è±å¯Œçš„èªè€…ç‰¹å¾µã€‚
    2. **Maintain Isolation:** ç¢ºä¿æ¨¡å‹åœ¨æ¸¬è©¦æ™‚é‡åˆ°çš„ã€Œèªè€…ã€æ˜¯è¨“ç·´æ™‚å¾æœªè½éçš„ (Unseen Speakers)ï¼Œç¬¦åˆçœŸå¯¦å ´æ™¯éœ€æ±‚ã€‚
 
## Experiments

<img width="943" height="499" alt="image" src="https://github.com/user-attachments/assets/4df26d54-d97b-49d9-9840-34f81d3cf92b" />

#### 1. In-Context Learning (ICL) Performance
ä½œè€…é©—è­‰äº† LLM èˆ‡ LALM é€é Few-shot Prompting å®Œæˆ SLU ä»»å‹™çš„èƒ½åŠ›ã€‚

* **Capabilities (èƒ½åŠ›é©—è­‰):**
    * **IC (Intent Classification):** ç¢ºèªäº† LLMs å…·å‚™å®Œæˆæ­¤ä»»å‹™çš„æ½›åŠ›ï¼Œä¸¦å°‡çµè«–å»¶ä¼¸è‡³æœ€æ–°çš„ LALMsã€‚
    * **SF (Slot Filling) - The Surprise:** é€éç²¾å¿ƒè¨­è¨ˆçš„ Prompt ï¼Œæ¨¡å‹åœ¨ SF ä»»å‹™ä¸Šçš„è¡¨ç¾è¶…å‡ºé æœŸã€‚
        * *Text Input F1:* **55.09%**
        * *Speech Input F1:* **47.38%**
        * *Comparison:* é¡¯è‘—å„ªæ–¼å‰äººç ”ç©¶å ±å‘Šçš„ 13.35%ã€‚
* **The "Reality Check" (ç¾å¯¦çš„éª¨æ„Ÿ):**
    å„˜ç®¡ F1 çœ‹èµ·ä¾†ä¸éŒ¯ï¼Œä½† **Overall Accuracy (æ•´é«”æº–ç¢ºç‡)** å³ä½¿æ˜¯æœ€å¼·çš„æ¨¡å‹ (Qwen3-32B, GPT-4o-Audio) ä¹Ÿ **æœªè¶…é 15%**ã€‚
    * *Insight:* é€™å†æ¬¡è­‰æ˜äº† **MAC-SLU** è³‡æ–™é›†çš„é›£åº¦èˆ‡è¤‡é›œæ€§ï¼ˆMulti-intent å¸¶ä¾†çš„æŒ‘æˆ°ï¼‰ã€‚

#### 2. E2E LALMs vs. Pipeline Systems (ç«¯å°ç«¯ vs. æµæ°´ç·š)
é€™æ˜¯æœ¬ç¯‡è«–æ–‡æœ€é—œéµçš„æ¶æ§‹å°æ¯”ç™¼ç¾ã€‚

* **Comparable Performance (æ•ˆèƒ½ç›¸ç•¶):**
    E2E LALMs çš„è¡¨ç¾å·²ç¶“å¯ä»¥åª²ç¾ç”šè‡³è¶…è¶ŠåŒé‡ç´šçš„ Pipeline ç³»çµ±ã€‚
    * **Evidence:** `Qwen2.5-Omni-7B` (E2E) $\succ$ `Whisper + Qwen3-8B` (Pipeline)ã€‚
    * **Gains:** IC +2%, SF +1%ã€‚
* **Why E2E Wins? (æ ¸å¿ƒåŸå› ):**
    * **Avoidance of ASR Error Propagation:** E2E æ¨¡å‹ç›´æ¥è™•ç†éŸ³è¨Šï¼Œé¿å…äº† Pipeline ä¸­ ASR è½éŒ¯å°è‡´ NLU æ¥è‘—éŒ¯çš„é€£é–åæ‡‰ã€‚

#### 3. Scaling & Model Types (æ¨¡å‹è¦æ¨¡èˆ‡é¡å‹)
* **Size Matters (Scaling Law):**
    é›–ç„¶ 7B çš„ E2E è´äº† 8B çš„ Pipelineï¼Œä½†ä»è½å¾Œæ–¼æ›´å¤§çš„ `Qwen3-32B`ã€‚
    * *Implication:* æœªä¾†å°‡ LALM æ“´å¤§åƒæ•¸è¦æ¨¡ (Scaling up)ï¼Œæœ‰å·¨å¤§çš„æ•ˆèƒ½æå‡ç©ºé–“ã€‚
* **Closed vs. Open Source:**
    * `GPT-4o-Audio` & `Gemini-2.5-Flash` (é–‰æº) ç›®å‰åœ¨æ•´é«”æº–ç¢ºç‡ä¸Šä»å„ªæ–¼é–‹æº LALMsã€‚
 
<img width="452" height="326" alt="image" src="https://github.com/user-attachments/assets/6f347a1d-3923-4bd6-a4b4-d326e7a1d36e" />

#### 1. SFT vs. ICL: The Gap is Massive (SFT çš„çµ•å°çµ±æ²»åŠ›)
å¯¦é©—æ•¸æ“šç„¡æƒ…åœ°è­‰æ˜ï¼Œåœ¨ç‰¹å®šé ˜åŸŸä»»å‹™ï¼ˆIn-domain SLUï¼‰ä¸Šï¼Œå¾®èª¿ (SFT) ä»ç„¶é å¼·æ–¼æç¤ºå·¥ç¨‹ (In-Context Learning)ã€‚

* **Performance Jump:** ä»¥ `Qwen2.5-Omni-7B` ç‚ºä¾‹ï¼ŒSFT å¸¶ä¾†çš„æå‡æ˜¯å·¨å¤§çš„ï¼š
    * **IC Accuracy:** $\uparrow$ **29%**
    * **SF F1 Score:** $\uparrow$ **39%**
    * **Overall Accuracy:** $\uparrow$ **47%** (å¹¾è¿‘ç¿»å€çš„æˆé•·)
* **Conclusion:** ç›®å‰è¦é”åˆ° SLU ä»»å‹™çš„æœ€ä½³æ•ˆèƒ½ (Optimal Performance)ï¼Œ**Fine-tuning ä»æ˜¯å”¯ä¸€è§£**ã€‚æœŸå¾… LLM Agent åƒ…é  ICL è‡ªä¸»å®Œæˆè¤‡é›œ SLU ä»»å‹™ä»æ˜¯ä¸€å€‹å·¨å¤§çš„æŒ‘æˆ°ã€‚

#### 2. The "Achilles' Heel" of Pipeline Systems: Error Propagation (æµæ°´ç·šç³»çµ±çš„é˜¿åŸºé‡Œæ–¯è…±)
é€™æ®µæ•¸æ“šé‡åŒ–äº† ASR éŒ¯èª¤å¦‚ä½•æ¯€æ‰ä¸€å€‹å¼·å¤§çš„ LLMã€‚

* **Baseline (Ideal Case):**
    * ç•¶è¼¸å…¥æ˜¯å®Œç¾çš„æ–‡å­— (Gold Text, CER=0%) æ™‚ï¼Œ`Qwen3-8B` è¡¨ç¾æœ€å¥½ï¼ŒOverall Accuracy é”åˆ° **60.73%**ã€‚
* **Reality (ASR Errors):**
    ä¸€æ—¦æ¥ä¸Š ASRï¼Œæ•ˆèƒ½å°±æœƒå› ç‚º **Character Error Rate (CER)** çš„ä¸Šå‡è€ŒåŠ‡çƒˆä¸‹é™ï¼š
    * **Paraformer (CER=3.64%):** æº–ç¢ºç‡ä¸‹é™ **>13%**ã€‚
    * **Whisper (CER=10.40%):** æº–ç¢ºç‡ä¸‹é™ **>25%** (ç›´æ¥è…°æ–¬)ã€‚
* **Insight:**
    $$\text{High CER} \xrightarrow{\text{Propagates}} \text{Low NLU Accuracy}$$
    é€™è§£é‡‹äº†ç‚ºä»€éº¼ Pipeline æ–¹æ³•é›–ç„¶å¾ˆå¼·ï¼Œä½†åœ¨ç«¯å°ç«¯è©•æ¸¬ä¸­å¾€å¾€è¼¸çµ¦ LALMsâ€”â€”å› ç‚º **LALMs æ²’æœ‰ ASR è½‰éŒ„é€™å€‹ä¸­é–“ç’°ç¯€ï¼Œå¤©ç”Ÿå…ç–«è½‰éŒ„éŒ¯èª¤**ã€‚

### Qualitative Analysis: The "False Negative" Problem (å®šæ€§åˆ†æï¼šè¢«èª¤åˆ¤çš„éŒ¯èª¤)

<img width="919" height="344" alt="image" src="https://github.com/user-attachments/assets/e3c1b93e-92a1-46f0-b1ea-13c3744bba68" />

#### 1. The Phenomenon: Lexical Variation (ç”¨è©å·®ç•°)
ä½œè€…åœ¨åˆ†æéŒ¯èª¤æ¡ˆä¾‹æ™‚ç™¼ç¾ï¼Œå¤§é‡çš„æ‰€è¬‚ã€ŒéŒ¯èª¤ã€å…¶å¯¦æ˜¯è¢«å†¤æ‰çš„ã€‚
* **Observation:** æ¨¡å‹è¼¸å‡ºçš„ç­”æ¡ˆåœ¨ **èªæ„ä¸Šæ˜¯æ­£ç¢ºçš„ (Semantically Correct)**ï¼Œåªæ˜¯**æªè¾­ (Phrasing)** è·Ÿæ¨™æº–ç­”æ¡ˆï¼ˆLabelï¼‰ä¸ä¸€æ¨£ã€‚
* **Example:**
    * *Label:* "Open the window."
    * *Model Output:* "Please open the window."
    * *Metric Result:* **Error (X)** (å› ç‚ºå­—ä¸²ä¸å®Œå…¨åŒ¹é…)ã€‚

#### 2. Functional Correctness vs. Exact Match (åŠŸèƒ½æ­£ç¢ºæ€§ vs. ç²¾ç¢ºåŒ¹é…)
å¾ SLU çš„æ‡‰ç”¨ç›®æ¨™ä¾†çœ‹ï¼Œé€™äº›è¼¸å‡ºå…¶å¯¦æ˜¯åˆæ ¼çš„ã€‚
* **Goal:** SLU çš„ç›®çš„æ˜¯æå–èªæ„ä¾›ä¸‹æ¸¸æ‡‰ç”¨åŸ·è¡Œ (Execute downstream tasks)ã€‚
* **Verdict:** åªè¦èªæ„å°äº†ï¼Œæ©Ÿå™¨å°±èƒ½åŸ·è¡Œæ­£ç¢ºå‹•ä½œã€‚å› æ­¤ï¼Œé€™äº›è¢«åˆ¤éŒ¯çš„æ¨£æœ¬åœ¨çœŸå¯¦æ‡‰ç”¨ä¸­å…¶å¯¦æ˜¯ **Functionally Correct (åŠŸèƒ½ä¸Šæ­£ç¢ºçš„)**ã€‚

#### 3. Conclusion: Underestimation of Capability (èƒ½åŠ›è¢«ä½ä¼°)
é€™å°å‡ºäº†ä¸€å€‹é—œéµçµè«–ï¼š
$$\text{Standard Metrics (Exact Match)} \xrightarrow{\text{Leads to}} \text{Underestimation}$$
ä¾è³´ã€Œç²¾ç¢ºå­—ä¸²åŒ¹é…ã€çš„å‚³çµ±è©•æ¸¬æ¨™æº–ï¼Œåš´é‡ä½ä¼°äº† LALM çœŸå¯¦çš„æ„åœ–ç†è§£èƒ½åŠ›ã€‚å› ç‚º LALM æ˜¯ç”Ÿæˆå¼æ¨¡å‹ï¼Œå¤©ç”Ÿå°±æ¯”å‚³çµ±åˆ†é¡æ¨¡å‹æ›´å…·å‰µé€ æ€§èˆ‡å¤šæ¨£æ€§ã€‚

---
### ğŸ“ Conclusion & Future Directions (çµè«–èˆ‡æœªä¾†æ–¹å‘)

#### 1. Summary of Contributions (è²¢ç»ç¸½çµ)
* **New Dataset (MAC-SLU):** ç™¼å¸ƒäº†ä¸€å€‹é‡å°è»Šè¼‰å ´æ™¯ (Automotive Cabin) çš„ **Chinese Multi-Intent SLU** è³‡æ–™é›†ï¼Œè§£æ±ºäº†ç¾æœ‰è³‡æ–™é›†ç¼ºä¹å¤šæ¨£æ€§èˆ‡è¤‡é›œåº¦çš„å•é¡Œã€‚
* **Unified Benchmark:** å»ºç«‹äº†ä¸€å€‹çµ±ä¸€çš„è©•æ¸¬åŸºæº–ï¼Œè®“ Open-source LLMs èˆ‡ LALMs èƒ½åœ¨åŒä¸€å€‹æ¨™æº–ä¸‹é€²è¡Œæ¯”è¼ƒã€‚

#### 2. Key Takeaways (æ ¸å¿ƒçµè«–)
* **SFT is Key:** é›–ç„¶ In-context learning (ICL) å±•ç¾äº†æ½›åŠ›ï¼Œä½†åœ¨è¿½æ±‚ **Optimal Performance (æœ€ä½³æ•ˆèƒ½)** æ™‚ï¼Œ**In-domain SFT (é ˜åŸŸå…§å¾®èª¿)** ä»ç„¶æ˜¯ä¸å¯æˆ–ç¼ºçš„é—œéµã€‚
* **E2E Potential:** ç«¯å°ç«¯ (E2E) LALMs çš„è¡¨ç¾å·²ç¶“å¯ä»¥åª²ç¾å‚³çµ±çš„ Pipeline æ–¹æ³•ã€‚
    * *Reason:* æœ‰æ•ˆæ¸›è¼•äº† **ASR Error Propagation (è½‰éŒ„éŒ¯èª¤å‚³æ’­)** çš„å½±éŸ¿ã€‚

#### 3. Future Work (æœªä¾†å±•æœ›)
ä½œè€…æŒ‡å‡ºäº†æ¥ä¸‹ä¾†çš„ç ”ç©¶é‡é»ï¼š
* **Enhancing ICL:** æå‡æ¨¡å‹åœ¨ In-context learning ä¸‹çš„èƒ½åŠ›ï¼ˆè®“æ¨¡å‹ä¸ç”¨å¾®èª¿ä¹Ÿèƒ½è¡¨ç¾æ›´å¥½ï¼‰ã€‚
* **Semantically-aligned Metrics:** é–‹ç™¼æ›´ç¬¦åˆèªæ„å°é½Šçš„è©•ä¼°æŒ‡æ¨™ï¼ˆä¸å†åªçœ‹å­—ä¸²æ˜¯å¦å®Œå…¨åŒ¹é…ï¼Œè€Œæ˜¯çœ‹æ„æ€å°ä¸å°ï¼‰ã€‚
