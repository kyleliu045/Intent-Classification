# MAC-SLU: Multi-Intent Automotive Cabin Spoken Language Understanding Benchmark

> **ğŸ’¡ Meta Information**
>
> * **Venue:** `arXiv 2025` 
> * **Paper Type:** Benchmark
> * **Links:** [Paper (arXiv)](https://arxiv.org/abs/2512.01603) | [Code](https://github.com/Gatsby-web/MAC_SLU) | [Dataset](https://huggingface.co/datasets/Gatsby1984/MAC_SLU)
> * **Institutions:** Shanghai Jiao Tong University, AISpeech Co., Ltd., et al.
>
> **ğŸ·ï¸ Domains & Tasks**
> * `Spoken Language Understanding` `Multi-Intent Understanding` `LLMs` `Large Audio Language Models`
> * **Core Tasks:** Intent Classification, Multi-Intent Detection

### ğŸ“Œ Citation
```text
Peng, Y., Cai, C., Liu, Z., Fan, S., Jiang, S., Xu, H., et al. (2025). 
MAC-SLU: Multi-Intent Automotive Cabin Spoken Language Understanding Benchmark. 
arXiv preprint arXiv:2512.01603.
```

## Introduction

### ğŸ“ Spoken Language Understanding (SLU) - Core Definition
> Spoken Language Understanding (SLU) is a conventional paradigm for task-oriented spoken semantics extraction, which has been
widely applied in scenarios such as smart homes and automobiles to extract spoken commands from users for executing downstream tasks.

#### 1. Definition (å®šç¾©)
SLU æ˜¯ **Task-oriented (ä»»å‹™å°å‘)** å°è©±ç³»çµ±ä¸­çš„æ ¸å¿ƒç¯„å¼ï¼Œè² è²¬é€²è¡Œ **Spoken Semantics Extraction (å£èªèªæ„æå–)**ã€‚
* **The Mapping Process:**
    $$\text{User Speech} \xrightarrow{\text{SLU}} \text{Structured Semantics (Commands)}$$
    (ç›®æ¨™æ˜¯å°‡éçµæ§‹åŒ–çš„èªéŸ³è¨Šè™Ÿï¼Œè½‰åŒ–ç‚ºæ©Ÿå™¨å¯åŸ·è¡Œçš„çµæ§‹åŒ–æŒ‡ä»¤)

#### 2. Key Applications (ä¸»è¦æ‡‰ç”¨å ´æ™¯)
ç›®å‰å»£æ³›æ‡‰ç”¨æ–¼éœ€è¦ã€Œå…æ‰‹æŒæ“ä½œ (Hands-free)ã€çš„å ´æ™¯ï¼š
* ğŸ  **Smart Homes (æ™ºæ…§å®¶å±…):** e.g., "Turn off the lights."
* ğŸš— **Automobiles (è»Šè¼‰ç³»çµ±):** e.g., "Navigate to the nearest gas station."

#### 3. Purpose (ç›®çš„)
ç‚ºäº†åŸ·è¡Œ **Downstream Tasks (ä¸‹æ¸¸ä»»å‹™)**ã€‚
* SLU ä¸æ˜¯çµ‚é»ï¼Œè€Œæ˜¯æ‰‹æ®µã€‚å®ƒçš„æº–ç¢ºåº¦ç›´æ¥æ±ºå®šäº†ç³»çµ±èƒ½å¦æ­£ç¢ºåŸ·è¡Œä½¿ç”¨è€…çš„æ„åœ– (Execute spoken commands)ã€‚

### ğŸ“ SLU Architecture Evolution (SLU æ¶æ§‹æ¼”é€²)
> Traditional SLU employs a pipeline approach, first transcribing the userâ€™s spoken query into text via Automatic Speech Recognition (ASR), and then extracting semantic information through Natural Language Understanding (NLU), which typically includes Intent Classification (IC) and Slot Filling (SF). Subsequently, E2E SLU systems emerged to address the issue of error propagation from the ASR transcription process and potentially incorporate pre-trained language models (e.g., RoBERTa) to enhance performance.

#### 1. Traditional Pipeline Approach (å‚³çµ±æµæ°´ç·šå¼)
é€™æ˜¯æœ€ç¶“å…¸çš„è™•ç†æ–¹å¼ï¼Œå°‡ä»»å‹™æ‹†è§£ç‚ºå…©å€‹ç¨ç«‹éšæ®µï¼š

* **Workflow (å·¥ä½œæµç¨‹):** `Audio` --(ASR)--> `Text` --(NLU)--> `Semantics`
* **Key Components (æ ¸å¿ƒçµ„ä»¶):**
    1.  **ASR (Automatic Speech Recognition):** å°‡ä½¿ç”¨è€…çš„èªéŸ³æŸ¥è©¢è½‰éŒ„ç‚ºæ–‡å­—ã€‚
    2.  **NLU (Natural Language Understanding):** å¾è½‰éŒ„çš„æ–‡å­—ä¸­æå–èªæ„è³‡è¨Šï¼Œé€šå¸¸åŒ…å«å…©å€‹å­ä»»å‹™ï¼š
        * **IC (Intent Classification):** æ„åœ–åˆ†é¡ã€‚
        * **SF (Slot Filling):** é—œéµè©æ§½ä½å¡«å……ã€‚
* **Critical Issue (é—œéµå•é¡Œ):**
    * **Error Propagation (éŒ¯èª¤å‚³æ’­):** å¦‚æœ ASR åœ¨è½‰éŒ„éšæ®µç™¼ç”ŸéŒ¯èª¤ï¼ˆè½éŒ¯ï¼‰ï¼ŒNLU éšæ®µå°±å¹¾ä¹ä¸å¯èƒ½æ­£ç¢ºåˆ†æèªæ„ã€‚

#### 2. End-to-End (E2E) SLU (ç«¯å°ç«¯å¼)
ç‚ºäº†å…‹æœå‚³çµ±æµæ°´ç·šæ–¹æ³•çš„ç¼ºé™·è€Œå‡ºç¾çš„æ–°æ¶æ§‹ã€‚

* **Core Objective (æ ¸å¿ƒç›®æ¨™):**
    * è§£æ±º ASR è½‰éŒ„éç¨‹å¸¶ä¾†çš„ **Error Propagation (éŒ¯èª¤å‚³æ’­)** å•é¡Œã€‚
* **Methodology (æ–¹æ³•è«–):**
    * ä¸å†ä¾è³´ä¸­é–“çš„æ–‡å­—è½‰éŒ„ï¼Œå˜—è©¦ç›´æ¥å¾éŸ³è¨Šç‰¹å¾µæ˜ å°„åˆ°èªæ„ã€‚
    * ç¶“å¸¸çµåˆ **Pre-trained Language Models (PLMs)**ï¼ˆæ–‡ä¸­èˆ‰ä¾‹ï¼š**RoBERTa**ï¼‰ä¾†å¢å¼·æ¨¡å‹çš„èªæ„ç†è§£æ•ˆèƒ½ã€‚

### ğŸš© Critical Challenges in LLM-based SLU (LLM æ‡‰ç”¨æ–¼ SLU çš„ç•¶å‰æŒ‘æˆ°)
> Presently, the advancement of LLMs and LALMs offers the potential for a more flexible and precise SLU. Nevertheless, research on LLM-based SLU still confronts the following two challenges: (1) Existing SLU datasets lack sufficient diversity and complexity. The widely used ATIS and SNIPS datasets contain only 16 and 7 intents, respectively, which limits the taskâ€™s difficulty, resulting in existing models already achieving over 95% accuracy in both IC and SF. SLURP dataset increases the number of intent and slot categories but remains confined to single-intent SLU tasks. (2) There is a lack of a unified benchmark for state-of-the-art (SOTA) open-source LLMs and LALMs. Although some studies have preliminarily explored the performance of LLMs like ChatGPT and Llama on certain SLU tasks, they have adopted different task formats (i.e., varying data formats, prompts, or training and alignment methods), leading to evaluation
results that cannot be fairly compared. Furthermore, existing research has been limited to pipeline-based methods and LLMs, without exploring E2E approaches and the most advanced LALMs.

å„˜ç®¡ LLM å’Œ LALM å±•ç¾äº†æ¥µå¤§çš„æ½›åŠ›ï¼Œä½†ç›®å‰çš„ç ”ç©¶é¢è‡¨å…©å¤§æ ¸å¿ƒç—›é»ï¼š

#### 1. Dataset Limitation: Lack of Complexity (è³‡æ–™é›†çš„ä¾·é™æ€§)
ç¾æœ‰çš„ SLU è³‡æ–™é›†éæ–¼ç°¡å–®ï¼Œç„¡æ³•åæ˜ çœŸå¯¦å ´æ™¯çš„è¤‡é›œåº¦ï¼Œå°è‡´æ¨¡å‹èƒ½åŠ›çœ‹èµ·ä¾†ã€Œè™›é«˜ã€ã€‚
* **Saturated Benchmarks (å·²é£½å’Œçš„åŸºæº–):**
    * å¸¸ç”¨è³‡æ–™é›†å¦‚ `ATIS` (17 intents) å’Œ `SNIPS` (7 intents) åˆ†é¡éå°‘ã€‚
    * **Consequence:** ç¾æœ‰æ¨¡å‹åœ¨ IC (Intent Classification) èˆ‡ SF (Slot Filling) ä¸Šæº–ç¢ºç‡å‡å·²è¶…é **95%**ï¼Œé›£ä»¥å€åˆ†æ–°æ¨¡å‹çš„å„ªåŠ£ã€‚
* **Complexity Gap:**
    * é›–ç„¶ `SLURP` å¢åŠ äº†é¡åˆ¥æ•¸é‡ï¼Œä½†ä»ä¾·é™æ–¼ **Single-Intent (å–®ä¸€æ„åœ–)** ä»»å‹™ï¼Œç¼ºä¹å¤šæ„åœ– (Multi-Intent) çš„æŒ‘æˆ°ã€‚

#### 2. Evaluation Crisis: Lack of Unified Benchmark (ç¼ºä¹çµ±ä¸€è©•æ¸¬æ¨™æº–)
ç›®å‰çš„ SOTA æ¨¡å‹è©•æ¸¬è™•æ–¼ã€Œå„è‡ªç‚ºæ”¿ã€çš„ç‹€æ…‹ï¼Œç¼ºä¹å…¬å¹³çš„æ¯”è¼ƒåŸºæº–ã€‚
* **Inconsistent Protocols:**
    * ç¾æœ‰ç ”ç©¶é›–ç„¶æ¸¬è©¦äº† ChatGPT æˆ– Llamaï¼Œä½†ä½¿ç”¨äº†ä¸åŒçš„ Data Formatsã€Prompts æˆ– Alignment methodsã€‚
    * **Result:** è©•æ¸¬çµæœç„¡æ³•é€²è¡Œå…¬å¹³çš„æ©«å‘å°æ¯” (Unfair comparison)ã€‚
* **Scope Limitation:**
    * ç›®å‰ç ”ç©¶å¤šé›†ä¸­åœ¨ **Pipeline-based** æ–¹æ³•ï¼Œå¿½ç•¥äº† **End-to-End (E2E)** æ–¹æ³•èˆ‡æœ€å…ˆé€² **LALMs** çš„æ½›åŠ›æ¢ç´¢ã€‚

---

ğŸ’¡ Keep in Mind
é€™æ®µè©±å…¶å¯¦æ˜¯åœ¨ç‚ºä½œè€…è‡ªå·±çš„è²¢ç» **(Contribution)** é‹ªè·¯ã€‚è®€åˆ°é€™è£¡ï¼Œä½ æ‡‰è©²é æœŸé€™ç¯‡è«–æ–‡æ¥ä¸‹ä¾†æœƒæå‡ºï¼š
1.  ä¸€å€‹æ›´é›£ã€æ›´å¤šæ¨£åŒ–ï¼ˆå¯èƒ½åŒ…å« Multi-Intentï¼‰çš„æ–°è³‡æ–™é›†ã€‚
2.  ä¸€å€‹çµ±ä¸€çš„ Benchmarkï¼ŒåŒæ™‚è©•æ¸¬ Pipeline vs. E2E ä»¥åŠ LLM vs. LALMã€‚

---
### ğŸš€ Core Contributions (æ ¸å¿ƒè²¢ç»)
> This work addresses these challenges with two steps. First, we introduce the Multi-Intent Automotive Cabin Spoken Language Understanding (MAC-SLU) dataset, a novel Chinese SLU corpus to overcome the complexity limitations of existing data. Derived from real-world automotive text commands with TTS-synthesized speech, it spans 8 domains, 81 intents, 192 slots, and includes multi-intent queries with up to 5 intents, creating a more rigorous testbed. Second, we establish a unified benchmark on MAC-SLU for SOTA
open-source LLMs and LALMs. Standardizing formats, tasks, and evaluation methods enables fair comparisons and provides a dependable reference for the community.

é€™ç¯‡è«–æ–‡æå‡ºäº†å…©å¤§è§£æ±ºæ–¹æ¡ˆä¾†æ‡‰å°ç¾æœ‰ SLU ç ”ç©¶çš„ä¸è¶³ï¼š

#### 1. The MAC-SLU Dataset (å…¨æ–°çš„è³‡æ–™é›†)
ç‚ºäº†è§£æ±ºç¾æœ‰è³‡æ–™é›†ç¼ºä¹è¤‡é›œåº¦èˆ‡å¤šæ¨£æ€§çš„å•é¡Œï¼Œä½œè€…ç™¼å¸ƒäº† **Multi-Intent Automotive Cabin Spoken Language Understanding (MAC-SLU)**ã€‚
* **Language:** Chinese (ä¸­æ–‡èªæ–™)ã€‚
* **Data Source:** æºè‡ªçœŸå¯¦ä¸–ç•Œçš„è»Šè¼‰æ–‡æœ¬æŒ‡ä»¤ï¼Œä¸¦é€é TTS (Text-to-Speech) åˆæˆèªéŸ³ã€‚
* **Scale & Complexity:**
    * **8** Domains (é ˜åŸŸ)
    * **81** Intents (æ„åœ–)
    * **192** Slots (æ§½ä½)
* **Key Innovation:** åŒ…å« **Multi-intent queries (å¤šæ„åœ–æŸ¥è©¢)**ï¼Œå–®å¥æœ€å¤šåŒ…å« **5** å€‹æ„åœ–ï¼Œå»ºç«‹äº†ä¸€å€‹æ›´åš´è‹›çš„æ¸¬è©¦å¹³å° (Rigorous testbed)ã€‚

#### 2. Unified Benchmark (çµ±ä¸€çš„è©•æ¸¬åŸºæº–)
é‡å° SOTA é–‹æº LLMs å’Œ LALMs å»ºç«‹äº†çµ±ä¸€çš„è©•æ¸¬æ¨™æº–ã€‚
* **Standardization:** çµ±ä¸€äº†è³‡æ–™æ ¼å¼ (Formats)ã€ä»»å‹™å®šç¾© (Tasks) èˆ‡è©•ä¼°æ–¹æ³• (Evaluation methods)ã€‚
* **Goal:** å¯¦ç¾ **Fair Comparisons (å…¬å¹³æ¯”è¼ƒ)**ï¼Œç‚ºç¤¾ç¾¤æä¾›å¯ä¿¡è³´çš„åƒè€ƒä¾æ“šã€‚

> Our contributions include:
> - We introduce MAC-SLU, a novel Chinese multi-intent SLU dataset including complex, multi-intent queries from a real-world automotive cabin domain. MAC-SLU enables a more chanllenging evaluation of the latest LLMs and LALMs.
> - We provide a comprehensive benchmark for SOTA open-source and closed-source LLMs and LALMs, encompassing methods based on direct inference, in-context learning, and SFT, as well as both pipeline and E2E SLU task paradigms.
> - Our experiments demonstrate that (1) existing LLMs and LALMs can complete parts of the IC or SF tasks through in-context learning, yet there remains a significant performance gap compared to in-domain SFT; (2) benefiting from the avoidance of error propagation, current LALMs can already achieve performance comparable to pipeline methods.

#### 1. Dataset Contribution: MAC-SLU
ä½œè€…ç™¼å¸ƒäº†ä¸€å€‹å…¨æ–°çš„ **Chinese Multi-Intent SLU Dataset**ã€‚
* **Domain:** Real-world Automotive Cabin (çœŸå¯¦è»Šè¼‰å ´æ™¯)ã€‚
* **Characteristics:** åŒ…å« **Complex, Multi-intent queries (è¤‡é›œå¤šæ„åœ–æŸ¥è©¢)**ã€‚
* **Value:** ç›¸æ¯”æ–¼ç¾æœ‰çš„ç°¡å–®è³‡æ–™é›†ï¼Œå®ƒç‚ºæœ€æ–°çš„ LLMs å’Œ LALMs æä¾›äº†æ›´å…·æŒ‘æˆ°æ€§çš„è©•æ¸¬ç’°å¢ƒã€‚

#### 2. Comprehensive Benchmark (å…¨é¢è©•æ¸¬åŸºæº–)
å»ºç«‹äº†ä¸€å€‹æ¶µè“‹ **SOTA Open-source & Closed-source** æ¨¡å‹çš„è©•æ¸¬åŸºæº–ã€‚
* **Models Covered:** LLMs (Text-only) & LALMs (Audio-Text).
* **Methods Evaluated:**
    * Direct Inference (Zero-shot)
    * In-Context Learning (Few-shot)
    * Supervised Fine-Tuning (SFT)
* **Paradigms:** åŒæ™‚è©•æ¸¬äº† **Pipeline (ASR+NLU)** èˆ‡ **E2E (End-to-End)** å…©ç¨® SLU æ¶æ§‹ã€‚

#### 3. Key Experimental Insights (é—œéµå¯¦é©—çµè«–)
é€™éƒ¨åˆ†æ­ç¤ºäº†ç›®å‰æŠ€è¡“çš„é‚Šç•Œ (Boundaries)ï¼š
* **Gap in Learning Paradigms:**
    $$\text{Performance}\_{\text{SFT}} \gg \text{Performance}\_{\text{ICL}}$$
    * é›–ç„¶ LLMs/LALMs å¯ä»¥é€é In-context Learning (ICL) å®Œæˆéƒ¨åˆ† IC æˆ– SF ä»»å‹™ï¼Œä½†èˆ‡ **In-domain SFT** ç›¸æ¯”ä»æœ‰é¡¯è‘—å·®è·ã€‚
* **Rise of LALMs (E2E Potential):**
    ç›®å‰çš„ LALMs (Large Audio Language Models) å·²ç¶“èƒ½é”åˆ°èˆ‡ Pipeline æ–¹æ³• **Comparable (ç›¸ç•¶)** çš„æ•ˆèƒ½ã€‚
    * **Reason:** æ­¸åŠŸæ–¼ **Avoidance of Error Propagation** (E2E æ¶æ§‹é¿å…äº† ASR è½‰éŒ„éŒ¯èª¤å‚³éåˆ° NLU çš„å•é¡Œ)ã€‚
